

\section{Notations and Preliminaries} \label{sec:prelims}

Let $X = \{x_1,\cdots,x_n\} $ be a set of propositional variables and let $F$ be a formula defined over $X$. A \textit{satisfying assignment} or a \textit{witness} of $F$ is an assignment of truth values to the variables in $X$ such that $F$ evaluates to true. Let $\#F$ denote the number of satisfying assignments of F. We say that $F$ is satisfiable (or SAT) if $\#F>0$ and unsatisfiable (or UNSAT) if $\#F=0$.
 
A single XOR constraint (also called a {\em XOR clause}) over $X$ is specified as $ a_{1}x_{1} \oplus a_{2}x_{2} \oplus \cdots \oplus a_{n}x_{n} = b_{0}$, where all $a_{i},b_{j} \in \{0,1\}$. 
Satisfiability of a system of $m$ XOR constraints (XORSAT) over $n$ variables can be thought of as a matrix $A \in \{0,1\}^{m \times n} $, a vector $b \in \{0,1\}^m$, and a variable vector $x \in \{0,1\}^n$ which satisfy $Ax=b$. The density $s$ of a system of $m$ XOR constraints is the ratio $s=m/n$. 


To generate a random XORSAT instance, we create such a matrix $A$ and the vector $b$ with each element either $0$ or $1$ with probability $\frac{1}{2}$.    
Let the random variable $\Q$ denote such a randomly generate XORSAT instance over $n$ with $\ceil{sn}$ XOR clauses, where $s=\frac{m}{n}$ is called the XOR density. On expectation
a XOR clause in such an instance would have $\frac{n}{2}$ variables.

An at-most-$k$ cardinality constraint is satisfiable by an assignment if and only if at most $k$ of the $n$ literals are set to \true by that assignment. The set of satisfying assignments for this constraint forms a Hamming ball of radius $k$, which has volume $\sum_{w=0}^{k} {{n} \choose {w}}$.
Let $\F$  represent the CNF encoding of the at-most-k cardinality constraint over $n$ variables. We will use $\#\F$ to represent the number of solutions to $\F$, $\#\F = \sum_{w=0}^{k} {{n} \choose {w}}$.  

A 1-CARD-XOR formula is the conjunction of some number of XOR clauses and a cardinality constraint. For fixed positive integers $k$ and $n$, and a fixed positive real number $s$, let the random variable $\FQ$ denote the formula $\Q \wedge \F$.

We use $\P{E}$ to denote the probability of an event $E$. 
We say that an infinite sequence of random events $E_1, E_2, \cdots $ occurs 
\emph{with high probability} (denoted, w.h.p.) if $\lim\limits_{n \to \infty} \P{E_n} = 1$.
Let $H(\mu)= - \mu\log_{2}(\mu)-(1-\mu)\log_{2}(1-\mu)$ denote the binary entropy function.
